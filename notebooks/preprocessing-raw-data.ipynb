{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.ndimage import gaussian_filter\nfrom scipy.spatial import KDTree\nimport numpy as np\nimport os\nimport glob\nfrom scipy import io\nimport cv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_DATA_PATH = '/kaggle/input/crowd-counting/crowd_dataset'\nWORK_DIR = '/kaggle/working/'\nPROCESSED_DATA_PATH = os.path.join(WORK_DIR, 'processed_data')\nos.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\nprint(f\"Dataset path: {BASE_DATA_PATH}\")\nprint(f\"Working directory: {WORK_DIR}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_gaussian_kernel(sigma, size):\n    if size % 2 == 0: size += 1\n    x = np.arange(0, size, 1, float); y = x[:, np.newaxis]\n    x0 = y0 = size // 2\n    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n    return g / g.sum()\n\ndef create_density_map_optimized(image_shape, points, beta=0.3, k=4):\n    height, width = image_shape[:2]\n    density_map = np.zeros((height, width), dtype=np.float32)\n    if len(points) == 0:\n        return density_map\n    valid_points = [p for p in points if 0 <= p[0] < width and 0 <= p[1] < height]\n    points = np.array(valid_points)\n    \n\n    if len(points) == 0:\n        return density_map\n\n\n    if len(points) < k:\n        for x, y in points:\n            density_map[int(y), int(x)] = 1.0\n        return gaussian_filter(density_map, sigma=4)\n\n    tree =  KDTree(points)\n    distances, _ = tree.query( points, k=k )\n    avg_distances = np.mean(distances[:, 1:], axis=1 )\n    for i, (x , y) in enumerate(points):\n        x_int, y_int = int(x), int(y)\n        \n        sigma = max(1, beta *  avg_distances[i])\n        kernel_size = int(sigma * 6)\n        kernel = generate_gaussian_kernel(sigma,  kernel_size)\n\n        x_start = max(0, x_int - kernel_size // 2)\n        y_start = max(0, y_int - kernel_size // 2)\n        x_end = min(width, x_int + kernel_size // 2  + 1)\n        y_end = min(height, y_int + kernel_size // 2 + 1)\n        if x_end <= x_start or y_end <= y_start:\n            continue\n\n        k_x_start = max(0, kernel_size // 2 - x_int)\n        k_y_start = max(0, kernel_size // 2 - y_int)\n        k_x_end = k_x_start + (x_end - x_start)\n        k_y_end = k_y_start + (y_end - y_start)\n        density_map[y_start:y_end, x_start:x_end] += kernel[k_y_start:k_y_end,  k_x_start:k_x_end ]\n    return density_map","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_and_save_data(image_folder, gt_folder, output_folder):\n    os.makedirs(output_folder, exist_ok=True)\n    image_paths = sorted(glob.glob(os.path.join(image_folder, '*.jpg')))\n    for img_path in image_paths:\n        basename = os.path.basename(img_path).replace('.jpg', '')\n        gt_path = os.path.join(gt_folder, f'GT_{basename}.mat')\n        output_file = os.path.join(output_folder, f\"{basename}.npy\")\n        if os.path.exists(output_file):\n            continue\n        image = cv2.imread(img_path)\n        try:\n            mat = io.loadmat(gt_path)\n            points = mat['image_info'][0, 0][0, 0][0]\n        except Exception as e:\n            print(f\"Error loading {gt_path}: {e}\")\n            continue\n        density_map = create_density_map_optimized(image.shape, points, beta = 0.2)\n        np.save(output_file, density_map)\n    print(f\"Finished preprocessing for {image_folder}\")\n    \npreprocess_and_save_data(\n    image_folder=os.path.join(BASE_DATA_PATH, 'train_data/images'),\n    gt_folder=os.path.join(BASE_DATA_PATH, 'train_data/ground_truth'),\n    output_folder=os.path.join(PROCESSED_DATA_PATH, 'train'))\n\npreprocess_and_save_data(\n    image_folder=os.path.join(BASE_DATA_PATH, 'test_data/images'),\n    gt_folder=os.path.join(BASE_DATA_PATH, 'test_data/ground_truth'),\n    output_folder=os.path.join(PROCESSED_DATA_PATH, 'test'))\nprint(\"--- Preprocessing Complete ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n    return FileLink(file_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_dir()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}